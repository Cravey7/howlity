{
  "name": "Howlity MCP Server",
  "description": "A server for managing Supabase operations",
  "version": "1.0.0",
  "commands": [
    {
      "name": "init",
      "description": "Initialize Supabase client",
      "implementation": "async function init(args) { const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key. Please provide them as arguments or set environment variables.' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); return { success: true, message: 'Supabase client initialized successfully', client: supabase }; } catch (error) { return { error: `Failed to initialize Supabase client: ${error.message}` }; } }"
    },
    {
      "name": "query",
      "description": "Execute a query on a Supabase table",
      "implementation": "async function query(args) { if (!args.table) { return { error: 'Table name is required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); let query = supabase.from(args.table).select(args.select || '*'); if (args.where) { query = query.match(args.where); } if (args.order) { query = query.order(args.order.column, { ascending: args.order.ascending }); } if (args.limit) { query = query.limit(args.limit); } const { data, error } = await query; if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Query failed: ${error.message}` }; } }"
    },
    {
      "name": "insert",
      "description": "Insert data into a Supabase table",
      "implementation": "async function insert(args) { if (!args.table || !args.data) { return { error: 'Table name and data are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.from(args.table).insert(args.data).select(); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Insert failed: ${error.message}` }; } }"
    },
    {
      "name": "update",
      "description": "Update data in a Supabase table",
      "implementation": "async function update(args) { if (!args.table || !args.data || !args.match) { return { error: 'Table name, data, and match criteria are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.from(args.table).update(args.data).match(args.match).select(); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Update failed: ${error.message}` }; } }"
    },
    {
      "name": "delete",
      "description": "Delete data from a Supabase table",
      "implementation": "async function delete_data(args) { if (!args.table || !args.match) { return { error: 'Table name and match criteria are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.from(args.table).delete().match(args.match).select(); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Delete failed: ${error.message}` }; } }"
    },
    {
      "name": "create_table",
      "description": "Create a new table in Supabase database",
      "implementation": "async function create_table(args) { if (!args.table || !args.columns) { return { error: 'Table name and columns definition are required' }; } const { Pool } = require('pg'); try { const connectionString = args.connectionString || process.env.SUPABASE_DIRECT_URL; if (!connectionString) { return { error: 'Missing database connection string' }; } const pool = new Pool({ connectionString }); const client = await pool.connect(); // Build the CREATE TABLE SQL statement let columnsSQL = []; for (const column of args.columns) { if (!column.name || !column.type) { client.release(); return { error: 'Each column must have a name and type' }; } let columnDef = `\"${column.name}\" ${column.type}`; if (column.primaryKey) columnDef += ' PRIMARY KEY'; if (column.notNull) columnDef += ' NOT NULL'; if (column.unique) columnDef += ' UNIQUE'; if (column.default !== undefined) columnDef += ` DEFAULT ${column.default}`; if (column.references) columnDef += ` REFERENCES ${column.references}`; columnsSQL.push(columnDef); } const createTableSQL = `CREATE TABLE IF NOT EXISTS \"${args.table}\" (${columnsSQL.join(', ')});`; await client.query(createTableSQL); // Add RLS policies if specified if (args.enableRLS) { await client.query(`ALTER TABLE \"${args.table}\" ENABLE ROW LEVEL SECURITY;`); } client.release(); return { success: true, message: `Table '${args.table}' created successfully` }; } catch (error) { return { error: `Create table failed: ${error.message}` }; } }"
    },
    {
      "name": "drop_table",
      "description": "Delete a table from Supabase database",
      "implementation": "async function drop_table(args) { if (!args.table) { return { error: 'Table name is required' }; } const { Pool } = require('pg'); try { const connectionString = args.connectionString || process.env.SUPABASE_DIRECT_URL; if (!connectionString) { return { error: 'Missing database connection string' }; } const pool = new Pool({ connectionString }); const client = await pool.connect(); const dropTableSQL = `DROP TABLE IF EXISTS \"${args.table}\" ${args.cascade ? 'CASCADE' : ''};`; await client.query(dropTableSQL); client.release(); return { success: true, message: `Table '${args.table}' dropped successfully` }; } catch (error) { return { error: `Drop table failed: ${error.message}` }; } }"
    },
    {
      "name": "auth_signup",
      "description": "Sign up a new user with Supabase Auth",
      "implementation": "async function auth_signup(args) { if (!args.email || !args.password) { return { error: 'Email and password are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.auth.signUp({ email: args.email, password: args.password, options: args.options }); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Signup failed: ${error.message}` }; } }"
    },
    {
      "name": "auth_signin",
      "description": "Sign in a user with Supabase Auth",
      "implementation": "async function auth_signin(args) { if (!args.email || !args.password) { return { error: 'Email and password are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.auth.signInWithPassword({ email: args.email, password: args.password }); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Signin failed: ${error.message}` }; } }"
    },
    {
      "name": "auth_signout",
      "description": "Sign out a user with Supabase Auth",
      "implementation": "async function auth_signout(args) { const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { error } = await supabase.auth.signOut(); if (error) throw error; return { success: true, message: 'User signed out successfully' }; } catch (error) { return { error: `Signout failed: ${error.message}` }; } }"
    },
    {
      "name": "storage_upload",
      "description": "Upload a file to Supabase Storage",
      "implementation": "async function storage_upload(args) { if (!args.bucket || !args.path || !args.file) { return { error: 'Bucket, path, and file are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.storage.from(args.bucket).upload(args.path, args.file, { cacheControl: args.cacheControl || '3600', upsert: args.upsert || false }); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Upload failed: ${error.message}` }; } }"
    },
    {
      "name": "storage_download",
      "description": "Get a download URL for a file in Supabase Storage",
      "implementation": "async function storage_download(args) { if (!args.bucket || !args.path) { return { error: 'Bucket and path are required' }; } const { createClient } = require('@supabase/supabase-js'); const supabaseUrl = args.url || process.env.NEXT_PUBLIC_SUPABASE_URL; const supabaseKey = args.key || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY; if (!supabaseUrl || !supabaseKey) { return { error: 'Missing Supabase URL or API key' }; } try { const supabase = createClient(supabaseUrl, supabaseKey); const { data, error } = await supabase.storage.from(args.bucket).download(args.path); if (error) throw error; return { success: true, data }; } catch (error) { return { error: `Download failed: ${error.message}` }; } }"
    },
    {
      "name": "direct_connection",
      "description": "Create a direct connection to Supabase PostgreSQL database",
      "implementation": "async function direct_connection(args) { const { Pool } = require('pg'); try { const pool = new Pool({ connectionString: args.connectionString || process.env.SUPABASE_DIRECT_URL }); const client = await pool.connect(); const result = await client.query(args.query || 'SELECT NOW()'); client.release(); return { success: true, data: result.rows }; } catch (error) { return { error: `Direct connection failed: ${error.message}` }; } }"
    },
    {
      "name": "transaction_pooler",
      "description": "Connect using transaction pooler (ideal for serverless functions)",
      "implementation": "async function transaction_pooler(args) { const { Pool } = require('pg'); try { const pool = new Pool({ connectionString: args.connectionString || process.env.SUPABASE_TRANSACTION_POOLER_URL }); const client = await pool.connect(); const result = await client.query(args.query || 'SELECT NOW()'); client.release(); return { success: true, data: result.rows, message: 'Transaction pooler connection successful' }; } catch (error) { return { error: `Transaction pooler connection failed: ${error.message}` }; } }"
    },
    {
      "name": "session_pooler",
      "description": "Connect using session pooler (for IPv4 networks)",
      "implementation": "async function session_pooler(args) { const { Pool } = require('pg'); try { const pool = new Pool({ connectionString: args.connectionString || process.env.SUPABASE_SESSION_POOLER_URL }); const client = await pool.connect(); const result = await client.query(args.query || 'SELECT NOW()'); client.release(); return { success: true, data: result.rows, message: 'Session pooler connection successful' }; } catch (error) { return { error: `Session pooler connection failed: ${error.message}` }; } }"
    },
    {
      "name": "get_file_content",
      "description": "Get the content of a file in the workspace",
      "implementation": "async function get_file_content(args) { if (!args.path) { return { error: 'File path is required' }; } try { const fs = require('fs'); const path = require('path'); const filePath = path.resolve(args.path); const content = fs.readFileSync(filePath, 'utf8'); return { success: true, content }; } catch (error) { return { error: `Failed to read file: ${error.message}` }; } }"
    },
    {
      "name": "list_files",
      "description": "List files in a directory",
      "implementation": "async function list_files(args) { const directory = args.directory || '.'; try { const fs = require('fs'); const path = require('path'); const dirPath = path.resolve(directory); const files = fs.readdirSync(dirPath); return { success: true, files }; } catch (error) { return { error: `Failed to list files: ${error.message}` }; } }"
    },
    {
      "name": "search_files",
      "description": "Search for files containing specific text",
      "implementation": "async function search_files(args) { if (!args.query) { return { error: 'Search query is required' }; } const directory = args.directory || '.'; try { const fs = require('fs'); const path = require('path'); const glob = require('glob'); const files = glob.sync('**/*', { cwd: directory, nodir: true, ignore: args.ignore || ['**/node_modules/**', '**/.git/**'] }); const results = []; for (const file of files) { const filePath = path.join(directory, file); const content = fs.readFileSync(filePath, 'utf8'); if (content.includes(args.query)) { results.push({ file, path: filePath }); } } return { success: true, results }; } catch (error) { return { error: `Search failed: ${error.message}` }; } }"
    },
    {
      "name": "InitializeProject",
      "description": "Sets up a new project with standard folder structures, config files, and dependencies",
      "implementation": "async function InitializeProject(args) { const template = args.template || 'nextjs'; const installDependencies = args.install_dependencies !== false; const setupGit = args.setup_git !== false; try { const fs = require('fs'); const { execSync } = require('child_process'); let command = ''; if (template === 'nextjs') { command = `npx create-next-app . --typescript --tailwind --eslint --app --src-dir`; } else if (template === 'react') { command = `npx create-react-app . --template typescript`; } else if (template === 'express') { command = `mkdir -p src/routes src/controllers src/models src/middleware && npm init -y && npm install express typescript ts-node @types/express @types/node`; } else { return { error: `Unsupported template: ${template}` }; } console.log(`Initializing ${template} project...`); execSync(command, { stdio: 'inherit' }); if (setupGit && !fs.existsSync('.git')) { console.log('Setting up Git repository...'); execSync('git init && git add . && git commit -m \"Initial commit\"', { stdio: 'inherit' }); } return { success: true, message: `Project initialized with ${template} template` }; } catch (error) { return { error: `Project initialization failed: ${error.message}` }; } }"
    },
    {
      "name": "CleanProject",
      "description": "Removes unused files, temp files, and old logs to keep the project tidy",
      "implementation": "async function CleanProject(args) { const preserveGit = args.preserve_git !== false; const removeNodeModules = args.remove_node_modules === true; const clearLogs = args.clear_logs !== false; try { const fs = require('fs'); const path = require('path'); const { execSync } = require('child_process'); const filesToRemove = []; // Find temp files and logs if (clearLogs) { console.log('Cleaning log files and temporary files...'); const tempPatterns = ['*.log', '*.tmp', '.DS_Store', 'npm-debug.log*', 'yarn-debug.log*', 'yarn-error.log*']; tempPatterns.forEach(pattern => { try { const files = execSync(`find . -name \"${pattern}\" ${preserveGit ? '-not -path \"*/.git/*\"' : ''}`).toString().split('\\n').filter(Boolean); filesToRemove.push(...files); } catch (e) { console.log(`Warning: Could not search for pattern ${pattern}`); } }); } // Remove node_modules if requested if (removeNodeModules && fs.existsSync('node_modules')) { console.log('Removing node_modules directory...'); execSync('rm -rf node_modules', { stdio: 'inherit' }); } // Remove identified files filesToRemove.forEach(file => { if (file && fs.existsSync(file)) { fs.unlinkSync(file); console.log(`Removed: ${file}`); } }); return { success: true, message: 'Project cleaned successfully', removedFiles: filesToRemove }; } catch (error) { return { error: `Project cleanup failed: ${error.message}` }; } }"
    },
    {
      "name": "FormatCode",
      "description": "Runs Prettier/ESLint to standardize code formatting",
      "implementation": "async function FormatCode(args) { const formatter = args.formatter || 'prettier'; const fixErrors = args.fix_errors !== false; try { const { execSync } = require('child_process'); let command = ''; if (formatter === 'prettier') { command = `npx prettier --write \"**/*.{js,jsx,ts,tsx,json,css,scss,md}\" ${fixErrors ? '' : '--check'}`; } else if (formatter === 'eslint') { command = `npx eslint . --ext .js,.jsx,.ts,.tsx ${fixErrors ? '--fix' : ''}`; } else if (formatter === 'black') { command = `black . ${fixErrors ? '' : '--check'}`; } else { return { error: `Unsupported formatter: ${formatter}` }; } console.log(`Running ${formatter}...`); const output = execSync(command, { stdio: 'pipe' }).toString(); return { success: true, message: `Code formatted with ${formatter}`, output }; } catch (error) { return { error: `Formatting failed: ${error.message}` }; } }"
    },
    {
      "name": "MinifyAssets",
      "description": "Minifies JS, CSS, and images for optimized performance",
      "implementation": "async function MinifyAssets(args) { const minifyJs = args.minify_js !== false; const minifyCss = args.minify_css !== false; const compressImages = args.compress_images !== false; try { const { execSync } = require('child_process'); // Install required dependencies if not already installed console.log('Installing required dependencies...'); execSync('npm install --save-dev terser cssnano imagemin', { stdio: 'inherit' }); if (minifyJs) { console.log('Minifying JavaScript files...'); execSync('npx terser --compress --mangle --output dist/bundle.min.js -- src/**/*.js', { stdio: 'inherit' }); } if (minifyCss) { console.log('Minifying CSS files...'); execSync('npx postcss src/**/*.css --use cssnano --dir dist/', { stdio: 'inherit' }); } if (compressImages) { console.log('Compressing images...'); execSync('npx imagemin images/* --out-dir=dist/images', { stdio: 'inherit' }); } return { success: true, message: 'Assets minified successfully' }; } catch (error) { return { error: `Asset minification failed: ${error.message}` }; } }"
    },
    {
      "name": "OptimizeDependencies",
      "description": "Removes unused dependencies and updates outdated ones",
      "implementation": "async function OptimizeDependencies(args) { const updateDependencies = args.update_dependencies !== false; const removeUnused = args.remove_unused !== false; try { const { execSync } = require('child_process'); if (removeUnused) { console.log('Checking for unused dependencies...'); execSync('npm install --save-dev depcheck', { stdio: 'inherit' }); const depcheckOutput = execSync('npx depcheck').toString(); const unusedDeps = depcheckOutput.match(/Unused dependencies\\s*\\n(.+)/s); if (unusedDeps && unusedDeps[1]) { const depsToRemove = unusedDeps[1].trim().split('\\n').map(d => d.trim()); if (depsToRemove.length > 0) { console.log(`Removing unused dependencies: ${depsToRemove.join(', ')}`); execSync(`npm uninstall ${depsToRemove.join(' ')}`, { stdio: 'inherit' }); } } } if (updateDependencies) { console.log('Updating outdated dependencies...'); const outdatedOutput = execSync('npm outdated --json', { stdio: 'pipe' }).toString(); const outdated = JSON.parse(outdatedOutput || '{}'); const packagesToUpdate = Object.keys(outdated); if (packagesToUpdate.length > 0) { console.log(`Updating dependencies: ${packagesToUpdate.join(', ')}`); execSync('npm update', { stdio: 'inherit' }); } } return { success: true, message: 'Dependencies optimized successfully' }; } catch (error) { return { error: `Dependency optimization failed: ${error.message}` }; } }"
    },
    {
      "name": "RunSecurityAudit",
      "description": "Checks for vulnerabilities in dependencies and code",
      "implementation": "async function RunSecurityAudit(args) { const scanDependencies = args.scan_dependencies !== false; const scanCodebase = args.scan_codebase !== false; try { const { execSync } = require('child_process'); let results = {}; if (scanDependencies) { console.log('Scanning dependencies for vulnerabilities...'); const auditOutput = execSync('npm audit --json', { stdio: 'pipe' }).toString(); results.dependencies = JSON.parse(auditOutput || '{}'); } if (scanCodebase) { console.log('Installing code security scanner...'); execSync('npm install --save-dev eslint-plugin-security', { stdio: 'inherit' }); console.log('Scanning codebase for security issues...'); try { const eslintOutput = execSync('npx eslint . --plugin security --ext .js,.jsx,.ts,.tsx', { stdio: 'pipe' }).toString(); results.codebase = { issues: eslintOutput }; } catch (eslintError) { results.codebase = { issues: eslintError.stdout.toString() }; } } return { success: true, message: 'Security audit completed', results }; } catch (error) { return { error: `Security audit failed: ${error.message}` }; } }"
    },
    {
      "name": "OptimizeBuild",
      "description": "Runs build optimizations for production",
      "implementation": "async function OptimizeBuild(args) { const treeShaking = args.tree_shaking !== false; const bundleSplitting = args.bundle_splitting !== false; const optimizeImages = args.optimize_images !== false; try { const fs = require('fs'); const { execSync } = require('child_process'); // Check if this is a Next.js project const isNextJs = fs.existsSync('next.config.js') || fs.existsSync('next.config.mjs'); if (isNextJs) { console.log('Detected Next.js project, optimizing build configuration...'); let nextConfig = ''; if (fs.existsSync('next.config.js')) { nextConfig = fs.readFileSync('next.config.js', 'utf8'); } else if (fs.existsSync('next.config.mjs')) { nextConfig = fs.readFileSync('next.config.mjs', 'utf8'); } else { nextConfig = 'module.exports = { reactStrictMode: true };'; } // Add optimizations to Next.js config if (treeShaking && !nextConfig.includes('transpilePackages')) { nextConfig = nextConfig.replace('module.exports = {', 'module.exports = { swcMinify: true,'); } if (bundleSplitting && !nextConfig.includes('chunks')) { nextConfig = nextConfig.replace('module.exports = {', 'module.exports = { webpack: (config) => { config.optimization.splitChunks = { chunks: \"all\" }; return config; },'); } if (optimizeImages && !nextConfig.includes('images')) { nextConfig = nextConfig.replace('module.exports = {', 'module.exports = { images: { minimumCacheTTL: 60, formats: [\"image/webp\"] },'); } fs.writeFileSync('next.config.js', nextConfig); console.log('Running optimized production build...'); execSync('npm run build', { stdio: 'inherit' }); } else { // Generic webpack optimization console.log('Setting up webpack optimizations...'); if (!fs.existsSync('webpack.config.js')) { const webpackConfig = `module.exports = { mode: 'production', optimization: { minimize: true, ${treeShaking ? 'usedExports: true,' : ''} ${bundleSplitting ? 'splitChunks: { chunks: \"all\" },' : ''} }, ${optimizeImages ? 'module: { rules: [{ test: /\\.(png|jpg|gif|svg)$/, use: [{ loader: \"image-webpack-loader\", options: { mozjpeg: { progressive: true }, optipng: { enabled: true }, pngquant: { quality: [0.65, 0.90], speed: 4 }, gifsicle: { interlaced: false } } }] },' : ''} };`; fs.writeFileSync('webpack.config.js', webpackConfig); } console.log('Running optimized production build...'); execSync('npm run build', { stdio: 'inherit' }); } return { success: true, message: 'Build optimized successfully' }; } catch (error) { return { error: `Build optimization failed: ${error.message}` }; } }"
    },
    {
      "name": "DeployProject",
      "description": "Deploys the project to a staging or production environment",
      "implementation": "async function DeployProject(args) { const environment = args.environment || 'staging'; const deployMethod = args.deploy_method || 'vercel'; try { const { execSync } = require('child_process'); if (deployMethod === 'vercel') { console.log(`Deploying to Vercel (${environment})...`); execSync(`npx vercel ${environment === 'production' ? '--prod' : ''}`, { stdio: 'inherit' }); } else if (deployMethod === 'netlify') { console.log(`Deploying to Netlify (${environment})...`); execSync(`npx netlify deploy ${environment === 'production' ? '--prod' : ''}`, { stdio: 'inherit' }); } else if (deployMethod === 'docker') { console.log(`Building and deploying Docker image (${environment})...`); const tag = environment === 'production' ? 'latest' : 'staging'; execSync(`docker build -t myapp:${tag} . && docker push myapp:${tag}`, { stdio: 'inherit' }); } else { return { error: `Unsupported deployment method: ${deployMethod}` }; } return { success: true, message: `Deployed to ${environment} using ${deployMethod}` }; } catch (error) { return { error: `Deployment failed: ${error.message}` }; } }"
    },
    {
      "name": "ExecuteTests",
      "description": "Runs unit and integration tests",
      "implementation": "async function ExecuteTests(args) { const testFramework = args.test_framework || 'jest'; const coverage = args.coverage === true; try { const { execSync } = require('child_process'); let command = ''; if (testFramework === 'jest') { command = `npx jest ${coverage ? '--coverage' : ''}`; } else if (testFramework === 'mocha') { command = `npx mocha ${coverage ? '--coverage' : ''}`; } else if (testFramework === 'pytest') { command = `python -m pytest ${coverage ? '--cov=.' : ''}`; } else { return { error: `Unsupported test framework: ${testFramework}` }; } console.log(`Running tests with ${testFramework}...`); const output = execSync(command, { stdio: 'pipe' }).toString(); return { success: true, message: 'Tests executed successfully', output }; } catch (error) { return { error: `Test execution failed: ${error.message}`, output: error.stdout ? error.stdout.toString() : '' }; } }"
    },
    {
      "name": "RunDebugger",
      "description": "Starts a debugging session with necessary logs",
      "implementation": "async function RunDebugger(args) { const breakOnException = args.break_on_exception !== false; const verboseLogging = args.verbose_logging !== false; try { const { execSync, spawn } = require('child_process'); const fs = require('fs'); const path = require('path'); // Create debug configuration if it doesn't exist const vscodePath = path.join('.vscode'); const launchPath = path.join(vscodePath, 'launch.json'); if (!fs.existsSync(vscodePath)) { fs.mkdirSync(vscodePath); } if (!fs.existsSync(launchPath)) { const launchConfig = { version: '0.2.0', configurations: [{ type: 'node', request: 'launch', name: 'Debug Current File', program: '${file}', skipFiles: ['<node_internals>/**'], ${breakOnException ? 'stopOnEntry: true,' : ''} }] }; fs.writeFileSync(launchPath, JSON.stringify(launchConfig, null, 2)); console.log('Created debug configuration in .vscode/launch.json'); } // Set environment variables for verbose logging if (verboseLogging) { process.env.DEBUG = '*'; process.env.NODE_DEBUG = 'http,net,stream'; console.log('Enabled verbose logging'); } // Start the debugger console.log('Starting debugger...'); if (process.env.TERM_PROGRAM === 'vscode') { execSync('code --open-url \"vscode://workbench/debug\"', { stdio: 'inherit' }); } else { console.log('To start debugging:'); console.log('1. Open your project in VS Code'); console.log('2. Press F5 or go to Run > Start Debugging'); } return { success: true, message: 'Debugger configured and ready' }; } catch (error) { return { error: `Debugger setup failed: ${error.message}` }; } }"
    },
    {
      "name": "GenerateBoilerplate",
      "description": "Generates templates for components, APIs, or entire modules",
      "implementation": "async function GenerateBoilerplate(args) { const type = args.type || 'component'; const framework = args.framework || 'nextjs'; try { const fs = require('fs'); const path = require('path'); let template = ''; let filePath = ''; if (framework === 'nextjs') { if (type === 'component') { const componentName = args.name || 'MyComponent'; filePath = path.join('src', 'components', `${componentName}.tsx`); template = `'use client';\n\nimport React from 'react';\n\ninterface ${componentName}Props {\n  title?: string;\n}\n\nexport default function ${componentName}({ title = 'Default Title' }: ${componentName}Props) {\n  return (\n    <div className=\"p-4 border rounded shadow-sm\">\n      <h2 className=\"text-xl font-semibold\">{title}</h2>\n      <p>Your component content here</p>\n    </div>\n  );\n}\n`; } else if (type === 'api') { const apiName = args.name || 'example'; filePath = path.join('src', 'app', 'api', apiName, 'route.ts'); template = `import { NextResponse } from 'next/server';\n\nexport async function GET(request: Request) {\n  try {\n    // Your API logic here\n    return NextResponse.json({ message: 'Success', data: [] });\n  } catch (error) {\n    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 });\n  }\n}\n\nexport async function POST(request: Request) {\n  try {\n    const body = await request.json();\n    // Process the request body\n    return NextResponse.json({ message: 'Created successfully', data: body });\n  } catch (error) {\n    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 });\n  }\n}\n`; } else if (type === 'model') { const modelName = args.name || 'User'; filePath = path.join('src', 'models', `${modelName}.ts`); template = `export interface ${modelName} {\n  id: string;\n  name: string;\n  email: string;\n  createdAt: Date;\n  updatedAt: Date;\n}\n\nexport function create${modelName}(data: Omit<${modelName}, 'id' | 'createdAt' | 'updatedAt'>) {\n  return {\n    id: crypto.randomUUID(),\n    ...data,\n    createdAt: new Date(),\n    updatedAt: new Date(),\n  };\n}\n`; } } else if (framework === 'express') { if (type === 'api') { const routeName = args.name || 'users'; filePath = path.join('src', 'routes', `${routeName}.ts`); template = `import express from 'express';\nimport { get${routeName.charAt(0).toUpperCase() + routeName.slice(1)}, create${routeName.charAt(0).toUpperCase() + routeName.slice(1)} } from '../controllers/${routeName}';\n\nconst router = express.Router();\n\nrouter.get('/', get${routeName.charAt(0).toUpperCase() + routeName.slice(1)});\nrouter.post('/', create${routeName.charAt(0).toUpperCase() + routeName.slice(1)});\n\nexport default router;\n`; const controllerPath = path.join('src', 'controllers', `${routeName}.ts`); const controllerTemplate = `import { Request, Response } from 'express';\n\nexport const get${routeName.charAt(0).toUpperCase() + routeName.slice(1)} = (req: Request, res: Response) => {\n  try {\n    // Your logic here\n    res.status(200).json({ message: 'Success', data: [] });\n  } catch (error) {\n    res.status(500).json({ message: 'Internal server error' });\n  }\n};\n\nexport const create${routeName.charAt(0).toUpperCase() + routeName.slice(1)} = (req: Request, res: Response) => {\n  try {\n    const data = req.body;\n    // Your logic here\n    res.status(201).json({ message: 'Created successfully', data });\n  } catch (error) {\n    res.status(500).json({ message: 'Internal server error' });\n  }\n};\n`; // Create the controller file as well const controllerDir = path.dirname(controllerPath); if (!fs.existsSync(controllerDir)) { fs.mkdirSync(controllerDir, { recursive: true }); } fs.writeFileSync(controllerPath, controllerTemplate); console.log(`Generated controller at ${controllerPath}`); } else if (type === 'model') { const modelName = args.name || 'User'; filePath = path.join('src', 'models', `${modelName}.ts`); template = `export interface ${modelName} {\n  id: string;\n  name: string;\n  email: string;\n  createdAt: Date;\n  updatedAt: Date;\n}\n\nexport class ${modelName}Model {\n  static async findAll() {\n    // Database query logic here\n    return [];\n  }\n\n  static async findById(id: string) {\n    // Database query logic here\n    return null;\n  }\n\n  static async create(data: Omit<${modelName}, 'id' | 'createdAt' | 'updatedAt'>) {\n    // Database insert logic here\n    return {\n      id: 'new-id',\n      ...data,\n      createdAt: new Date(),\n      updatedAt: new Date(),\n    };\n  }\n}\n`; } } // Create directory if it doesn't exist const dir = path.dirname(filePath); if (!fs.existsSync(dir)) { fs.mkdirSync(dir, { recursive: true }); } // Write the file fs.writeFileSync(filePath, template); return { success: true, message: `Generated ${type} for ${framework} at ${filePath}` }; } catch (error) { return { error: `Boilerplate generation failed: ${error.message}` }; } }"
    },
    {
      "name": "AICodeReview",
      "description": "Runs AI-powered code review for best practices",
      "implementation": "async function AICodeReview(args) { const focusArea = args.focus_area || 'readability'; try { const fs = require('fs'); const path = require('path'); const { execSync } = require('child_process'); // Define patterns to look for based on focus area let patterns = []; if (focusArea === 'performance') { patterns = [ { regex: /useState\\(\\[\\]\\)/g, message: 'Consider using useMemo for derived state from arrays' }, { regex: /useEffect\\(\\(\\)\\s*=>\\s*{[^}]*fetch\\(/g, message: 'Consider using React Query or SWR for data fetching' }, { regex: /map\\(.*=>.*<.*>\\)/g, message: 'Add key prop to mapped elements for better reconciliation' }, { regex: /new\\s+Array\\(/g, message: 'Use array literals [] instead of Array constructor' }, { regex: /\\+\\s*new\\s+Date\\(\\)/g, message: 'Use Date.now() instead of +new Date()' } ]; } else if (focusArea === 'security') { patterns = [ { regex: /dangerouslySetInnerHTML/g, message: 'Avoid dangerouslySetInnerHTML to prevent XSS attacks' }, { regex: /eval\\(/g, message: 'Avoid using eval() as it poses security risks' }, { regex: /document\\.write\\(/g, message: 'Avoid document.write() as it can enable XSS attacks' }, { regex: /\\s*href\\s*=\\s*[\"\\']javascript:/g, message: 'Avoid javascript: URLs as they can be exploited' }, { regex: /\\s*from\\s*[\"\\']express[\"\\'];(?![\\s\\S]*helmet)/g, message: 'Consider using helmet middleware with Express for security headers' } ]; } else { // readability patterns = [ { regex: /function\\s*\\([^)]*\\)\\s*{[\\s\\S]{100,}}/g, message: 'Function is too long, consider breaking it down' }, { regex: /if\\s*\\([^)]*\\)\\s*{[\\s\\S]*if\\s*\\([^)]*\\)\\s*{[\\s\\S]*if/g, message: 'Nested if statements make code hard to read, consider refactoring' }, { regex: /\\w{25,}/g, message: 'Variable/function name is too long, use more concise naming' }, { regex: /\\b[a-z]\\b(?!\\s*=>)/g, message: 'Single-letter variable names reduce readability' }, { regex: /\\btmp\\b|\\btemp\\b|\\bfoo\\b|\\bbar\\b/g, message: 'Avoid temporary variable names like tmp, temp, foo, bar' } ]; } // Find all relevant files const extensions = ['.js', '.jsx', '.ts', '.tsx']; const files = []; const findFiles = (dir) => { const entries = fs.readdirSync(dir, { withFileTypes: true }); for (const entry of entries) { const fullPath = path.join(dir, entry.name); if (entry.isDirectory() && entry.name !== 'node_modules' && entry.name !== '.git') { findFiles(fullPath); } else if (entry.isFile() && extensions.includes(path.extname(entry.name))) { files.push(fullPath); } } }; findFiles('.'); // Analyze files const issues = []; for (const file of files) { const content = fs.readFileSync(file, 'utf8'); for (const pattern of patterns) { const matches = content.match(pattern.regex); if (matches) { issues.push({ file, message: pattern.message, occurrences: matches.length }); } } } // Generate report const report = { focusArea, filesAnalyzed: files.length, issuesFound: issues.length, issues }; return { success: true, message: `AI code review completed for ${focusArea}`, report }; } catch (error) { return { error: `AI code review failed: ${error.message}` }; } }"
    }]
  }
